include ../common/mixin

article.main-article(data-page='math-for-ml')
  a#preface.in-page-anchor
  h1 機械学習のための数学

  .paragraph
    p
      | 機械学習のより深い理解に必要な数学の基礎についてまとめます。
      br
      small 2017/3/11現在加筆中です。内容は適宜追補します。
    p
      | このページで取り扱う記号の記法については
      a(href='http://www.deeplearningbook.org/contents/notation.html', target='_blank')
        | Goodfellow et al.(2016)
      | を踏襲します。

  .paragraph
    a#random-variable.in-page-anchor
    h4 Random variable - 確率変数
    h6 特徴
    ul.features
      li
        | 確率変数と書くと大仰で難解な概念に思えるが、英語名のRandom variableで覚えると理解しやすい。ただの取りうる値がランダムな変数。
        | Stocastic variableともいう。Stocasticは確率論的なという意味。
      li
        | 難しく書くと確率変数$X$は標本空間$\Omega$から可測空間$E$への可測関数。
      li
        | 身近な例ではコイン投げにおいて、標本空間$\Omega$は'表'と'裏'の2つの元を持つ集合ととれる。
        | '表'と'裏'のラベルのままだと数学的に扱いにくいので、通常は'表'=1, '裏'=0と標本空間の元に数を割り当てる。
        | この時標本空間に対応づけられている$\{0,1\}$が確率変数$X$の取りうる値の集合となる。
      li
        | 確率変数は離散値をとる場合と連続的な値をとる場合の2種類ある。
      li
        | 確率変数が離散的であるとは$X$の個数が有限または可算無限であることをいう。
      li
        | 確率変数が連続的であるとは$X$の個数が非可算であることをいう。
      li
        | 確率変数$X$の発生しやすさの確率分布関数$P(X)$が合わせて定義される。確率変数$X$の値そのものは確率(起こりやすさ)とは関係がない。

    h6 厳密な理解に必要な知識
    ul.prerequisite
      li
        a(href='https://en.wikipedia.org/wiki/Measure_(mathematics)', target='_blank') Measure Theory - 測度論
      li
        a(href='https://www.encyclopediaofmath.org/index.php/Measurable_space', target='_blank') Measuable Space - 可測空間
      li
        a(href='https://en.wikipedia.org/wiki/Measurable_function', target='_blank') Measure Function - 可測関数
      li
        a(href='https://en.wikipedia.org/wiki/Probability_space', target='_blank') Probability Space - 確率空間

  .paragraph
    a#probability-distribution.in-page-anchor
    h4 Probabiity distribution function - 確率分布関数

    h6 特徴
    ul.features
      li
        | 確率変数$X$の起こりやすさを表した関数。確率変数が離散的であるか連続的であるかによって確率分布関数の性質は異なる。
        | 前者の場合の確率分布関数をPMF(Probability Mass Function, 確率質量関数)と呼び、後者をPDF(Probability Density Function、 確率密度関数)と呼ぶ。
      li
        | PMFを考えるとき、一般に確率分布関数は大文字の$P$で表記される。
      li
        | PDFを考えるとき、一般に確率分布関数は小文字の$p$で表記される。
      li
        | $X$が確率分布関数$P$にしたがって分布するとき、
        | $$ X \sim P$$
        | と書く。

  .paragraph
    a#pmf.in-page-anchor
    h4 Discrete Probabiity distribution function - 離散確率分布関数

    h6 特徴
    ul.features
      li
        | $$ 0 \le P(X=x) \le 1 $$
      li
        | $$ \sum_{x \in X} P(x) = 1 $$
      li
        | $P(X=x)$は事象$x$の起こりえる確率をそのまま表す。

  .paragraph
    a#pdf.in-page-anchor
    h4 Continuous Probabiity distribution function - 連続確率分布関数

    h6 特徴
    ul.features
      li
        | $$ 0 \le p(X=x) $$
      li
        | $$ \int_{x \in X} p(x) dx = 1 $$
      li
        | $P(X=x)$は離散確率分布と異なり事象$x$の起こりえる確率を直接表さない。
        | 非可算無限個の元を持つ確率変数$X$に対して無限分の1である$X=x$をピンポイントで
        | 拾い上げる確率は限りなくゼロに近いため。
        | 通常は$X$上の連続区間$I \in [a,b]$を考え、区間$I$で表せられる事象が発生する確率を
        | $$ \int_{a}^{b} p(x) dx $$で表す。
      li
        | 連続確率分布の例として一様分布(Uniform Distribution)がある。これは確率分布関数が任意の閉区間$I \in [a,b]$において、
        | $$ p(x) = u(x;a,b) = \frac{1}{b-a}$$
        | で表される確率密度関数である。
        | 区間の長さのみによって確率が決まる非常にシンプルな分布関数である。

  .paragraph
    a#expectation.in-page-anchor
    h4 Expectation - 期待値

    h6 特徴
    ul.features
      li
        | 離散確率分布の場合:
        | $$ \mathbb{E}_{x \sim P}[f(x)] = \sum_{x} P(x) f(x) $$
      li
        | 連続確率分布の場合:
        | $$ \mathbb{E}_{x \sim P}[f(x)] = \int_{x} p(x) f(x) dx $$
      li
        | 線形性:
        | $$ \mathbb{E}_{x \sim P}[\alpha f(x) + \beta g(x)] = \alpha \mathbb{E}[f(x)] + \beta \mathbb{E}[g(X)] $$


  .paragraph
    a#self-information.in-page-anchor
    h4 Self Information - 自己情報量

    h6 特徴
    ul.features
      li
        | surprisalとも言う。情報の量を定義するために用いられる概念。
      li
        | $P(x)=1$、つまりわかりきっている情報は情報量ゼロとなる。
      li
        | まれな情報ほど自己情報量$I(x)$が大きい。
      li
        | 定義:
        | $$I(x) = - \log P(x)$$

  .paragraph
    a#entropy.in-page-anchor
    h4 Entropy - エントロピー

    h6 特徴
    ul.features
      li
        | 平均情報量とも言う。
      li
        | 自己情報量ではある単一の事象$x$における情報量しかわからなかったが、エントロピーの概念を用いれば、
        | 標本空間全体の情報量を定量することができる。
      li
        | 定義:
        | $$ H(X) = E_{X \sim P}[I(X)] = - \sum_{X \sim P} P(X) \ln{P(X)}$$
      li
        | $X \sim P$とすると、エントロピーは$$H(P)$$とも表記される。
      li
        | 起こりうる事象の数を固定すると、分布関数の選び方によってエントロピーの大小が変わる。
        | a個の事象を考えるとき、それぞれの事象の確率が等しく$1/a$である一様分布はこの事象のエントロピーを最大にする分布である。
        | これは事象の不確定さが最大ということを意味する。
        | 不確定さが小さくなるほどエントロピーも小さくなる。

  .paragraph
    a#kl-divergence.in-page-anchor
    h4 Kullback-Leibler divergence - カルバック・ライブラー情報量

    h6 特徴
    ul.features
      li
        | 2つの確率分布が互いにどれだけ異なっているかを表す指標。$D_{\text{KL}}$で表記される。
      li
        | $$ D_{\text{KL}}(P||Q) = E_{x \sim P}[\log \frac{P(x)}{Q(x)}] = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}$$
      li
        a(href='https://ja.wikipedia.org/wiki/%E3%82%AE%E3%83%96%E3%82%B9%E3%81%AE%E4%B8%8D%E7%AD%89%E5%BC%8F', target='_blank') ギブスの不等式
        | より、$D_{\text{KL}}(P||Q) \ge 0$ 。$D_{\text{KL}}(P||Q)=0$となるのは全ての$x$において$P(x)=Q(x)$となる場合のみ。
        br
        | つまり確率分布が互いに全く同一であるときにカルバック・ライブラー情報量は$0$になる。
      li
        | $$D_{\text{KL}}(P||Q) \ne D_{\text{KL}}(Q||P)$$

  .paragraph
    a#cross-entropy.in-page-anchor
    h4 Cross Entropy - クロスエントロピー

    h6 特徴
    ul.features
      li
        | 確率分布$P,Q$のクロスエントロピー$H(P,Q)$はエントロピー$H(P)$およびKL Divergenceを使うと下記の式で表せられる。
        | $$ H(P,Q) = H(P) + D_{\text{KL}}(P||Q) $$
      li
        | 上記を展開すると
        | $$
        | \begin{align}
        |   H(P,Q) &= -\sum_{x \sim P} P(x) \log P(x) + \sum_{x} P(x) \log \frac{P(x)}{Q(x)} \\
        |          &= -\sum_{x \sim P} P(x) \log Q(x)
        | \end{align}
        | $$
      li
        | Quadratic Cost Functionの場合、誤差の最小値は0となるがクロスエントロピーを誤差関数とする場合はその値の最小値はゼロとはならない。
        | とはいえクロスエントロピーを最小にすることとKL Divergenceを最小にすることは同義でありこの場合は最小値はゼロとなる。
        | そのためクロスエントロピーを最小化する、
        | といったときには誤差の測定に$H(P,Q)$と$D_{\text{KL}}$のどちらを使おうとしているのか注意が必要。
      li
        | 機械学習では入力がk個のクラスのうちどれに該当するか判定する場合に誤差関数として採用されることが多い。
        br
        | 2値分類(Binary Classification)を例として考える。入力が1であると考えられる確率を$\hat y_1$、2の場合は確率を$\hat y_2$とおく。
        | また、入力に対する真の判定結果をそれぞれ$y_1, y_2$とおく。このとき
        | $$
        | \begin{align}
        | H(P,Q) = - \sum_{i}^{2} y_i \log \hat{y_i} &= - (y_1 \log \hat{y_1} + y_2 \log \hat{y_2} ) \\
        | &= - (y_1 \log \hat{y_1} + (1-y_1) \log (1-\hat{y_1}) )
        | \end{align}
        | $$
        | となる。2値分類のため
        | $ y_2 = 1 - y1,\, \hat y_2 = 1 - \hat y_1$であることを利用している。
      li
        | MNISTのように10個の出力ニューロンが出力層に並べられている場合でも、出力層の1つ1つのニューロンはそれぞれ2値分類をしている。
        | 例えば出力層の最初のニューロンは入力が0かそうでないかを判断するニューロンであり、出力層の最後のニューロンは入力が9かそうでないかを
        | 判定するだけである。そのため上記の2値分類用のクロスエントロピーを用いて出力層のニューロンの誤差を定量できる。


  .paragraph
    a#logits.in-page-anchor
    h4 Logits - ロジット

    h6 特徴
    ul.features
      li
        | $$logit(p) = \ln \frac{p}{1-p}$$
      li
        | ロジットの逆関数はシグモイド関数$$\sigma(z)=1/(1+e^{-z})$$
        | つまり$$\sigma(logit(p)) = p$$
      li
        | $p/(1-p)$はオッズ(odds)と呼ばれる。
      li
        | 値域は$(-\infty, +\infty)$
      li
        | TensorflowではClassification APIにてsigmoid_cross_entropy_with_logitsのようにlogitsを使った分類メソッドが数多く登場するためここで紹介した。
      li
        | ロジット$\ln \frac{p}{1-p}$の値域は$(-\infty,+\infty)$であるため$logits \in \mathbf R$である。ロジットをシグモイド関数にかけると
        | $(-\infty,+\infty) \to (0,1)$に変換してくれるため、任意の実数を$[0,1]$に規格化する用途で頻繁に利用される。

  .paragraph
    a#softmax.in-page-anchor
    h4 Softmax - ソフトマックス

    h6 特徴
    ul.features
      li


+mathjax()